{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import library\n",
    "- http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/\n",
    "- http://learningtensorflow.com/index.html\n",
    "- http://suriyadeepan.github.io/2016-12-31-practical-seq2seq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Tensorflow basic\n",
    "\n",
    "- **tf.constant(), tf.Variable()**: 그래프의 객체\n",
    "- **tf.Session()/ tf.InteractiveSession()**: 그래프를 시작\n",
    "- **sess.run(c)**: 텐서 'c'를 계산 -> sess.close() 해야함\n",
    "- **with 절**: tf.Session()은 with 절과 사용, with 절에서 sess.close() 생략가능\n",
    "- **c.eval()**: sess.run(c)와 같음\n",
    "\n",
    "### - **tf.variable_scope()**\n",
    "- 모델에서 필요한 변수들을 관리하는 클래스(변수 범위 만들기)\n",
    "- tf.get_variable(): 직접호출 없이 변수를 가져오거나 생성(initializer 사용)\n",
    "- reuse = False: '현재 variable scope 이름 + 제공된 name'이 없으면 생성\n",
    "- reuse = True: '현재 variable scope 이름 + 제공된 name'이 있으면 반환\n",
    "- reuse = AUTO_REUSE: 둘다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create RNN Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding for each char in 'hello'\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cloud.githubusercontent.com/assets/901975/23348727/cc981856-fce7-11e6-83ea-4b187473466b.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Cell\n",
    "- tf.variable_scope('one_cell')이라는 객체 -> scope\n",
    "- cell 정의: 출력의 크기 = hidden_size\n",
    "- cell 구동: cell, 입력 data 넘겨주면 -> output, 마지막 state를 리턴\n",
    "- 연산은 graph로 표현: graph는 session 내에서 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n",
      "array([[[1., 0., 0., 0.]]], dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-3-de5d787e9152>:11: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "array([[[-0.26044506,  0.483253  ]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('one_cell', reuse=tf.AUTO_REUSE) as scope:\n",
    "    # One cell RNN input_dim (4) -> output_dim (2)\n",
    "    \n",
    "    hidden_size = 2\n",
    "    cell = tf.keras.layers.SimpleRNNCell(units=hidden_size)\n",
    "    # cell 정의: 출력의 크기 = hidden_size\n",
    "    print(cell.output_size, cell.state_size)\n",
    "\n",
    "    x_data = np.array([[h]], dtype=np.float32) # x_data = [[[1,0,0,0]]]\n",
    "    pp.pprint(x_data)\n",
    "    outputs, _states = tf.nn.dynamic_rnn(cell, x_data, dtype=tf.float32)\n",
    "    # cell 구동: cell, 입력 data 넘겨주면 -> output, 마지막 state를 리턴\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 연산 실행 전 initialize 수행\n",
    "    pp.pprint(outputs.eval())\n",
    "    # output: random한 weignt와 연산되어서 나온 값(dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cloud.githubusercontent.com/assets/901975/23383634/649efd0a-fd82-11e6-925d-8041242743b0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data = [h,e,l,l,o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 4)\n",
      "array([[[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]]], dtype=float32)\n",
      "array([[[ 0.5163382 ,  0.74790335],\n",
      "        [ 0.9169806 ,  0.8156855 ],\n",
      "        [ 0.5477242 ,  0.46063218],\n",
      "        [ 0.18679112,  0.21059105],\n",
      "        [-0.11483069, -0.19650726]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('two_sequances', reuse=tf.AUTO_REUSE) as scope:\n",
    "    # One cell RNN input_dim (4) -> output_dim (2). sequence: 5\n",
    "    hidden_size = 2\n",
    "    cell = tf.keras.layers.SimpleRNNCell(units=hidden_size)\n",
    "    # 셀 생성\n",
    "    \n",
    "    x_data = np.array([[h, e, l, l, o]], dtype=np.float32)\n",
    "    print(x_data.shape)  \n",
    "    pp.pprint(x_data)\n",
    "    # input data(1,5,4): sequence_length = 5\n",
    "    \n",
    "    outputs, _states = tf.nn.dynamic_rnn(cell, x_data, dtype=tf.float32)\n",
    "    # 셀 구동\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # initialize\n",
    "    pp.pprint(outputs.eval())\n",
    "    # output data(1,5,2) 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cloud.githubusercontent.com/assets/901975/23383681/9943a9fc-fd82-11e6-8121-bd187994e249.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple sequences (문자열 여러 개)\n",
    "- batch size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 4)\n",
      "array([[[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]],\n",
      "\n",
      "       [[0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.]],\n",
      "\n",
      "       [[0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.]]], dtype=float32)\n",
      "array([[[-0.5162457 ,  0.09800961],\n",
      "        [ 0.80118716, -0.24169545],\n",
      "        [ 0.6995623 ,  0.2410628 ],\n",
      "        [ 0.43763998, -0.04675321],\n",
      "        [ 0.23257603,  0.34301198]],\n",
      "\n",
      "       [[ 0.75176275,  0.2578723 ],\n",
      "        [-0.16892342,  0.47537887],\n",
      "        [ 0.54853654, -0.73256385],\n",
      "        [ 0.8891574 ,  0.21612257],\n",
      "        [ 0.39133072,  0.13524306]],\n",
      "\n",
      "       [[ 0.7525435 , -0.5251115 ],\n",
      "        [ 0.81592697,  0.30876702],\n",
      "        [ 0.3431359 ,  0.70552534],\n",
      "        [ 0.19034834,  0.2761002 ],\n",
      "        [ 0.5707368 , -0.48129925]]], dtype=float32)\n",
      "Tensor(\"3_batches/rnn/transpose_1:0\", shape=(3, 5, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('3_batches', reuse=tf.AUTO_REUSE) as scope:\n",
    "    # One cell RNN input_dim (4) -> output_dim (2). sequence: 5\n",
    "    hidden_size = 2\n",
    "    cell = tf.keras.layers.SimpleRNNCell(units=hidden_size)\n",
    "    # 셀 생성\n",
    "    \n",
    "    x_data = np.array([[h, e, l, l, o],\n",
    "                       [e, o, l, l, l],\n",
    "                       [l, l, e, e, l]], dtype=np.float32)\n",
    "    print(x_data.shape)  \n",
    "    pp.pprint(x_data)\n",
    "    # input data(3,5,4): sequence_length = 5\n",
    "    \n",
    "    outputs, _states = tf.nn.dynamic_rnn(cell, x_data, dtype=tf.float32)\n",
    "    # 셀 구동\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # initialize\n",
    "    pp.pprint(outputs.eval())\n",
    "    print(outputs)\n",
    "    # output data(3,5,2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LSTMCell (RNNCell 대신)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]],\n",
      "\n",
      "       [[0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.]],\n",
      "\n",
      "       [[0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.]]], dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-6-d4f526cdcd98>:10: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "array([[[-0.08025328, -0.02257276],\n",
      "        [-0.01457324,  0.00657582],\n",
      "        [ 0.02442009, -0.04039814],\n",
      "        [ 0.06362677, -0.07554006],\n",
      "        [ 0.03316153,  0.11248051]],\n",
      "\n",
      "       [[ 0.02678084,  0.02424256],\n",
      "        [ 0.00783703,  0.20369521],\n",
      "        [ 0.00514889,  0.09374549],\n",
      "        [ 0.        ,  0.        ],\n",
      "        [ 0.        ,  0.        ]],\n",
      "\n",
      "       [[ 0.03863546, -0.0461622 ],\n",
      "        [ 0.07485277, -0.07938247],\n",
      "        [ 0.06992196, -0.02149162],\n",
      "        [ 0.06991413,  0.00955858],\n",
      "        [ 0.        ,  0.        ]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('3_batches_dynamic_length', reuse=tf.AUTO_REUSE) as scope:\n",
    "    # One cell RNN input_dim (4) -> output_dim (5). sequence: 5, batch 3\n",
    "    # 3 batches 'hello', 'eolll', 'lleel'\n",
    "    x_data = np.array([[h, e, l, l, o],\n",
    "                       [e, o, l, l, l],\n",
    "                       [l, l, e, e, l]], dtype=np.float32)\n",
    "    pp.pprint(x_data)\n",
    "    \n",
    "    hidden_size = 2\n",
    "    cell = tf.nn.rnn_cell.LSTMCell(num_units=hidden_size, state_is_tuple=True)\n",
    "    outputs, _states = tf.nn.dynamic_rnn(\n",
    "        cell, x_data, sequence_length=[5,3,4], dtype=tf.float32)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pp.pprint(outputs.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost: sequence_loss\n",
    "- logits : 예측\n",
    "- targets : 정답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Loss:  0.5967595\n"
     ]
    }
   ],
   "source": [
    "# [batch_size, sequence_length]\n",
    "y_data = tf.constant([[1, 1, 1]])  # 정답\n",
    "\n",
    "# [batch_size, sequence_length, emb_dim ]\n",
    "prediction = tf.constant([[[0.2, 0.7], [0.6, 0.2], [0.2, 0.9]]], dtype=tf.float32)\n",
    "# -> one-hot: [1, 0, 1]\n",
    "\n",
    "# [batch_size * sequence_length]\n",
    "weights = tf.constant([[1, 1, 1]], dtype=tf.float32)\n",
    "\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(logits=prediction, targets=y_data, weights=weights)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(\"Loss: \", sequence_loss.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss1:  0.5130153\n",
      "Loss2:  0.3711007\n",
      "Loss3:  1.3132616\n",
      "Loss4:  0.31326166\n"
     ]
    }
   ],
   "source": [
    "# [batch_size, sequence_length]\n",
    "y_data = tf.constant([[1, 1, 1]])\n",
    "\n",
    "# [batch_size, sequence_length, emb_dim ]\n",
    "prediction1 = tf.constant([[[0.3, 0.7], [0.3, 0.7], [0.3, 0.7]]], dtype=tf.float32)\n",
    "# -> one-hot: [1, 1, 1]\n",
    "prediction2 = tf.constant([[[0.1, 0.9], [0.1, 0.9], [0.1, 0.9]]], dtype=tf.float32)\n",
    "# -> one-hot: [1, 1, 1] (하지만 정답에 더 가까움: loss작음)\n",
    "\n",
    "prediction3 = tf.constant([[[1, 0], [1, 0], [1, 0]]], dtype=tf.float32)\n",
    "# -> one-hot: [0, 0, 0] 모두 오답\n",
    "prediction4 = tf.constant([[[0, 1], [0, 1], [0, 1]]], dtype=tf.float32)\n",
    "# -> one-hot: [1, 1, 1] 모두 정답\n",
    "\n",
    "# [batch_size * sequence_length]\n",
    "weights = tf.constant([[1, 1, 1]], dtype=tf.float32)\n",
    "\n",
    "sequence_loss1 = tf.contrib.seq2seq.sequence_loss(prediction1, y_data, weights)\n",
    "sequence_loss2 = tf.contrib.seq2seq.sequence_loss(prediction2, y_data, weights)\n",
    "sequence_loss3 = tf.contrib.seq2seq.sequence_loss(prediction3, y_data, weights)\n",
    "sequence_loss4 = tf.contrib.seq2seq.sequence_loss(prediction4, y_data, weights)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(\"Loss1: \", sequence_loss1.eval())\n",
    "print(\"Loss2: \", sequence_loss2.eval())\n",
    "print(\"Loss3: \", sequence_loss3.eval())\n",
    "print(\"Loss4: \", sequence_loss4.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
